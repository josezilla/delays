{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Class Group Exercise Review | Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Review Exercise\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Other imports as you see fit (sklearn, etc)\n",
    "\n",
    "df = pd.read_csv('../datasets/titanic.csv')\n",
    "\n",
    "# Print a basic summary of the data\n",
    "print df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your objective:\n",
    "\n",
    "*Given a set of features for a passenger (as defined in the dataset) predict whether or not they will survive on the Titanic.*\n",
    "\n",
    "\n",
    "1. Perform any necessary conditioning or cleaning to the data\n",
    "2. Define the train/test split\n",
    "3. Choose and Define a model with all relevant parameters for that model\n",
    "4. Fit the model\n",
    "5. Determine the precision, recall, and F1 score for this model on the *training* dataset\n",
    "6. Predict whether passengers with the  following features survive:\n",
    "\n",
    "```\n",
    "     pclass     sex   age  sibsp  parch    ticket      fare cabin embarked\n",
    "          3  female   NaN      8      2   CA.2343   69.5500   NaN        S\n",
    "          3    male   NaN      0      0    349214    7.8958   NaN        S\n",
    "          3    male   NaN      0      0    349253    7.8958   NaN        C\n",
    "          1    male  44.0      2      0     19928   90.0000   C78        Q\n",
    "          2    male  31.0      0      0    244270   13.0000   NaN        S\n",
    "          1  female  31.0      0      2     36928  164.8667    C7        S\n",
    "          3  female  38.0      1      5    347077   31.3875   NaN        S\n",
    "          2    male  30.0      0      0     28228   13.0000   NaN        S\n",
    "          1    male   NaN      0      0   PC17757  227.5250   NaN        C\n",
    "          2  female  17.0      0      0    SC1748   12.0000   NaN        C\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Possible Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Perform any necessary conditioning or cleaning to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataframe):\n",
    "    is_male       = df['sex'].replace({'male': 1, 'female': 0})\n",
    "    estimated_age = df['age'].fillna(df['age'].mean())\n",
    "    \n",
    "    is_male.rename(\"is_male\", inplace=True)\n",
    "    estimated_age.rename(\"estimated_age\", inplace=True)\n",
    "\n",
    "    df_temp = pd.concat([dataframe, is_male, estimated_age], axis=1).drop(['sex', 'age'], axis=1)\n",
    "    \n",
    "    return pd.get_dummies(df_temp, columns=['pclass', 'embarked'])\n",
    "\n",
    "df_model = preprocess_data(df)\n",
    "\n",
    "df_model.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop(['survived', 'name', 'ticket', 'cabin'], axis=1)\n",
    "y = df_model['survived']  \n",
    "\n",
    "print \"Features:\"\n",
    "X.info();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We're just using a simple train/test split here. We can later use KFold for more robust modeling and validation later*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree, cross_validation, linear_model, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 & 4: Choose and Define a model with all relevant parameters for that model & fit the model\n",
    "\n",
    "*We'll define a simple function to help us display model results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is just a utility method to help print a summary of the results\n",
    "def format_model_results(sklearn_model, X_train, X_test, y_train, y_test):\n",
    "    # Get the model's class name (E.g. LogisticRegression, KNearestNeighbor, etc.) and store it to a string\n",
    "    model_class_name = sklearn_model.__class__.__name__  \n",
    "    \n",
    "    y_test_pred   = sklearn_model.predict(X_test)\n",
    "    y_train_pred  = sklearn_model.predict(X_train)\n",
    "\n",
    "    precision_score = metrics.precision_score(y_test_pred, y_test)\n",
    "    recall_score    = metrics.recall_score(y_test_pred, y_test)\n",
    "    f1_score        = metrics.f1_score(y_test_pred, y_test)\n",
    "    f1_score_train  = metrics.f1_score(y_train_pred, y_train)\n",
    "    auc_score       = metrics.roc_auc_score(y_test_pred, y_test)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "            \"Precision\": precision_score, \n",
    "            \"Recall\": recall_score, \n",
    "            \"F1 score\": f1_score, \n",
    "            \"F1 score (train)\": f1_score_train, \n",
    "            \"AUC\": auc_score\n",
    "        }, index=[model_class_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue;\">Logistic Regression</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a model and call it: logreg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try additional models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue;\">KNN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a model and call it: knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue;\">Decision Trees</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a model and call it: dectree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue;\">Random Forest Classifier</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a model and call it: rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.concat([\n",
    "    format_model_results(logreg_model, X_train, X_test, y_train, y_test),\n",
    "    format_model_results(knn_model, X_train, X_test, y_train, y_test),\n",
    "    format_model_results(dectree_model, X_train, X_test, y_train, y_test),\n",
    "    format_model_results(rf_model, X_train, X_test, y_train, y_test),\n",
    "])\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: green; text-decoration: underline;\">Note how simple it is to evaluate different models. Most of the work is in cleaning the data!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Part II: Improving the model\n",
    "\n",
    "This is a good start, but there are plenty of steps we can take to improve our results:\n",
    "\n",
    "2. **Feature Engineering:** We may be able to add \"synthetic\" information to our dataset by adding features from information already present. For instance, we discarded name, but perhaps we could get more information about a passenger by searching for keywords relating to honorifics and titles like 'Sir', 'Miss', 'Mrs', etc. This is called **feature engineering**\n",
    "\n",
    "1. **Parameter Tuning:** Modifying various parameters of our models may improve performance. For instance, for our RandomForest model we can control the complexity of our model by modifying `num_estimators`, `min_samples_leaf`, `max_features`, etc... *(See: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)*\n",
    "\n",
    "3. **Improved Cross Validation Techniques:** Because we're holding out 30% of our data for testing, we have less data samples on which to actually build our model. How can we address this?\n",
    "> **Example:** Use K-Fold cross validation. A larger value of k will allow us to keep more of our data for training, but will require training the same model multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement 1: Feature Engineering\n",
    "\n",
    "In our original analysis we dropped the `cabin`, `ticket`, and `name` columns. However, do these columns contain information that may improve our model?\n",
    "\n",
    "We can apply our own intelligence to try to add information to the dataset which are not present in the original feature space. We call this *feature engineering*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Get first character of values in the cabin column\n",
    "#    See: http://pandas.pydata.org/pandas-docs/stable/text.html?highlight=string\n",
    "# \n",
    "# Example: get_title(\"Braund, Mr. Owen Harris\")  # -> will return 'mr'\n",
    "def get_title(name):\n",
    "    titles = ['miss.','mrs.','master.','mr.','dr.','rev.','sir.','col.','lady.','archibald','major.','capt.']\n",
    "    \n",
    "    if name:\n",
    "        for title in titles:\n",
    "            if name.lower().find(title.lower()) > -1:\n",
    "                return title.replace(\".\", \"\")\n",
    "\n",
    "    return \"none\"\n",
    "\n",
    "def add_engineered_features(dataframe):\n",
    "    honorifics         = dataframe['name'].map(get_title)\n",
    "    cabin_prefixes     = dataframe['cabin'].str.get(0)\n",
    "    ticket_is_numeric  = dataframe['ticket'].str.isnumeric()\n",
    "    ticket_starts_with = dataframe['ticket'].str.get(0)\n",
    "\n",
    "    honorifics.rename('honorific', inplace=True)\n",
    "    cabin_prefixes.rename('cabin_prefix', inplace=True)\n",
    "    ticket_is_numeric.rename('ticket_is_numeric', inplace=True)\n",
    "    ticket_starts_with.rename('ticket_starts_with', inplace=True)\n",
    "\n",
    "    df_processed = pd.concat([dataframe, honorifics, cabin_prefixes, ticket_is_numeric, ticket_starts_with], axis=1)\n",
    "    df_processed = pd.get_dummies(df_processed, columns=['honorific', 'cabin_prefix', 'ticket_starts_with'])\n",
    "\n",
    "    return df_processed.drop(['name', 'cabin', 'ticket'], axis=1)\n",
    "\n",
    "# Clean the data:\n",
    "df_model = preprocess_data(df)\n",
    "df_model_improved = add_engineered_features(df_model)\n",
    "\n",
    "X = df_model_improved.drop('survived', axis=1)\n",
    "y = df_model_improved['survived']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Improvements 2 & 3: Evaluating the model with cross-validation and parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_folds = 20\n",
    "\n",
    "#\n",
    "#FILL HERE #\n",
    "#\n",
    "\n",
    "cv_score = cross_validation.cross_val_score(model_rf, X, y, cv=n_folds, scoring='roc_auc')\n",
    "\n",
    "print \"Avg AUC Score across %s folds: %s\" % (n_folds, cv_score.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
